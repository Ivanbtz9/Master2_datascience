\documentclass{beamer}

\usepackage[sfdefault]{cabin}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{graphicx}
%Police
%\usepackage[sfdefault]{roboto}
\usepackage[sfdefault]{FiraSans}

\definecolor{modernblue}{RGB}{70,130,180} 
\definecolor{modernvert}{RGB}{0, 80, 0} 

\usetheme{Madrid}

\usecolortheme[named=modernblue]{structure}

\setbeamertemplate{caption}{\insertcaption} % Utiliser le format de légende par défaut de Beamer

\title{UMAP : Uniform Manifold Approximation and Projection}
\author{Youness et Ivanhoé}
\date{28 octobre 2023}

\renewcommand{\thesection}{\Roman{section}}\renewcommand{\thesubsection}{\arabic{subsection} }\renewcommand{\thesubsubsection}{\alph{subsubsection} }

\newcommand{\C}{\mathbb{C}}\newcommand{\R}{\mathbb{R}}\newcommand{\Q}{\mathbb{Q}}\newcommand{\Z}{\mathbb{Z}}\newcommand{\N}{\mathbb{N}}\newcommand{\V}{\overrightarrow}\newcommand{\Cs}{\mathscr{C}}\newcommand{\Ps}{\mathscr{P}}\newcommand{\Rs}{\mathscr{R}}\newcommand{\Gs}{\mathscr{G}}\newcommand{\Ds}{\mathscr{D}}\newcommand{\happy}{\huge\smiley}\newcommand{\sad}{\huge\frownie}\newcommand{\alors}{\Large\Rightarrow}\newcommand{\equi}{\Leftrightarrow}
\newcommand{\disp}{\displaystyle}\newcommand{\Pro}{\mathbb{P}}


\newtheorem{thm}{Théorème}
\newtheorem{rmq}{Remarque}
\newtheorem{prop}{Propriété}
\newtheorem{cor}{Corollaire}
\newtheorem{lem}{Lemme}
\newtheorem{prop-def}{Propriété-définition}

\theoremstyle{definition}

\newtheorem{defi}{Définition}
\newtheorem{intro}{Initialisation}
\newtheorem{boucle}{Boucle principale}
\newtheorem{ex}{Exemple}
\newtheorem*{rap}{Rappel}
\newtheorem{cex}{Contre-exemple}
\newtheorem{exer}{Exercice} % \large {\fontfamily{ptm}\selectfont EXERCICE}
\newtheorem{nota}{Notation}
\newtheorem{ax}{Axiome}
\newtheorem{appl}{Application}
\newtheorem{csq}{Conséquence}
\def\di{\displaystyle}



\begin{document}
\begin{frame}[plain]
    \maketitle
\end{frame}


\begin{frame}
\frametitle{Introduction}

	\begin{minipage}[c]{1\linewidth}
	\begin{minipage}[t]{0.4\linewidth}\centering\begin{figure}
			\centering
			\includegraphics[scale=0.25]{swiss_roll.png}
			\caption{Représentation 3D du swiss roll dataset.}
	\end{figure}\end{minipage}\hfill 
	\begin{minipage}[t]{0.43\linewidth}\centering\begin{figure}
			\begin{center}
				\includegraphics[scale=0.27]{umap_swiss_roll.png}			
				\caption{UMAP projection (n\_neighbors=15, min\_dist = 0.1).}
			\end{center}
			
	\end{figure}\end{minipage}
	\end{minipage}
\textcolor{modernvert}{\textbf{Problématique :}} Comment fonctionne l'algorithme UMAP et pourquoi utiliser cette méthode sur un jeu de données ?
\end{frame}

\begin{frame}
	\tableofcontents
\end{frame}

\section{Les intérêts de la méthode UMAP sur un jeu de données}
\begin{frame}
	\frametitle{Les intérêts de la méthode UMAP sur un jeu de données}
	\begin{enumerate}[$\star$]
		\item Méthode de \emph{réduction de dimension} utile pour la visualisation des données.
		\item Projection dans un espace de plus petite dimension pour des données non-linéaires donc non-séparables par un sous-espace vectoriel. 
		\item Retransmettre dans un espace de plus petite dimension la structure topologique des données initiales. 
		\item Utile pour faire du clustering et peut servir pour entraîner des modèles de machine learning. 
	\end{enumerate}
	
\end{frame}

\begin{frame}
	\begin{minipage}[c]{1\linewidth}
		\begin{minipage}[t]{0.4\linewidth}\centering\begin{figure}
				\centering
				\includegraphics[scale=0.25]{acp_swiss_roll.png}
				\caption{Scatter plot de l'ACP du dataset swiss roll avec les deux premières composantes principales}
		\end{figure}\end{minipage}\hfill 
		\begin{minipage}[t]{0.43\linewidth}\centering\begin{figure}
				\begin{center}
					\includegraphics[scale=0.27]{umap2_swiss_roll.png}			
					\caption{UMAP projection du nuage de points dans un plan.\\ 
					(n\_neighbors=15, min\_dist = 0.1) }
				\end{center}
				
		\end{figure}\end{minipage}
	\end{minipage}
	
	
\end{frame}


\section{Présentation théorique de la méthode UMAP}
\begin{frame}
\frametitle{Présentation théorique de la méthode UMAP}
\begin{rmq}
	L'algorithme de UMAP ressemble à celui de T-SNE. Il est présenté comme plus rapide et pouvant s'adapter à une réduction de la dimension $d\geq2$. UMAP préserve aussi davantage la structure globale du jeu de donnés par rapport à T-SNE.
\end{rmq}
\quad \\[0.5cm]
	\textcolor{modernvert}{\textbf{Idée :}}\\ Pour un jeu de données $X\in\mathcal{M}_{n,p}(\R)$ nous cherchons préserver les relations locales entre les individus dans un espace de dimension plus petit ($d \lll p$). Cela revient à trouver $Y\in\mathcal{M}_{n,d}(\R)$ sous certaines contraintes.\\
	
	
\end{frame}

\begin{frame}
\textcolor{modernvert}{\textbf{Les étapes importantes :}}
\begin{enumerate}
	\item  Pour un nombre de voisins k fixé, donner pour tout couple d'individu $(x_i,x_j)$ une probabilité $p_{i,j}$ d'appartenir à un même voisinage.
	\item Initialiser la matrice $Y$ et en déduire la similarité entre les couples d'individu $(y_i,y_j)$ que l'on note $q_{i,j}$.
	\item Minimiser sur l'espace d'arrivée une fonction objectif d’entropie croisée qui mesure la dissimilarité entre les deux distributions $p$ et $q$. Ici $q$ est une fonction de $Y$.
\end{enumerate}	
	
\end{frame}

\subsection{Matrice de probabilités jointes sur l'espace de départ}
\begin{frame}
\frametitle{Matrice de probabilités jointes sur l'espace de départ}
\begin{enumerate}
	\item Fixons $k\geq 2$ le nombre de voisins à considérer. Soit $x_i,x_j$ deux individus, la similarité $p_{i|j}$ entre deux observations est définie par :$$p_{i|j} = \exp\left(-\dfrac{\|x_i -x_j\|_2-\rho_i}{\sigma_i}\right)$$

	\begin{itemize}
		\item  On définit $\rho_i = \underset{i\neq j}{\min}\|x_i-x_j\|$.
		\item On définit $\sigma_i$ de telle sorte que $\displaystyle \sum_{j=1}^{k}p_{i|i_j} = \log_2(k)$
	\end{itemize}
	\item Symétrisation pour obtenir la probabilité d'appartenir à un même voisinage : 
	$$p_{i,j} = p_{i|j} + p_{j|i} - p_{i|j} \times p_{j|i}$$ 
\end{enumerate}


	
\end{frame}

\subsection{Similarité entre les individus de l'espace d'arrivé}
\begin{frame}
	\frametitle{Similarité entre les individus de l'espace d'arrivé}
	Fixons une distance minimale \textit{"min\_dist"}.
	\begin{enumerate}
		\item Nous aimerions définir la similarité entre deux individus $y_i,y_j$ de la manière suivante : 
		
	 $$q_{i,j} = \left\{ \begin{array}{ccc}
			1 &\text{ si } & \|y_i-y_j\|\leq \textit{min\_dist}\\
			\exp(-\|y_i-y_j\|) &\text{ si } & \|y_i-y_j\|> \textit{min\_dist}
		\end{array}\right.$$
	
		\item Pour cela on s'inspire d'une loi de Student
		$$q_{i,j} = \left(1+ a\|y_i-y_j\|^{2b}\right)^{-1}$$ 
		L'algorithme UMAP optimise les deux paramètres $(a,b)$ pour coller au mieux à la fonctions précédente.  
	\end{enumerate}
	
	
\end{frame}

\subsection{Fonction d'entropie croisée et minimisation}
\begin{frame}
	\frametitle{Fonction d'entropie croisée et minimisation}

	\textcolor{modernvert}{\textbf{But :}} trouver la distribution des points $y_i$ dans l'espace d'arrivée telles que les similarités $q_{i,j}$ s'approchent le plus possibles des similarités $p_{i,j}$.
	\begin{itemize}
		\item Introduction de la fonction d’entropie croisée : 
		
	\end{itemize}
\begin{align*}
	CE(y_1,\cdots,y_n) =& \ CE(p,q) = \sum_{i=1}^{n}\sum_{j=1}^{n}p_{i,j}\ln\left(\dfrac{p_{i,j}}{q_{i,j}}\right) + (1-p_{i,j})\ln\left(\dfrac{(1-p_{i,j})}{(1 - q_{i,j})}\right)\\
	=&\  KL(p,q) + KL(1-p,1-q)
\end{align*}\quad\\[-0.25cm]
\begin{itemize}
		
		\item Minimiser la fonction d'entropie croisée à l'aide d'une descente de gradient stochastique :\\[-0.25cm]
		
		$$y_i : = y_i -\alpha \nabla_iCE (y_1,\cdots,y_i,\cdot,y_n)$$
		 
	\end{itemize}
	
		Pour la descente de Gradient Stochastique une seule observation est utilisée pour calculer le gradient à chaque itération et celle-ci est choisie de manière aléatoire.
	
\end{frame}


\section{Utiliser UMAP au quotidien et ses résultats}
\begin{frame}
	\frametitle{Utiliser UMAP au quotidien et ses résultats}
	
	
\end{frame}

\section{Conclusion et faiblesses de UMAP}

\begin{frame}
	\frametitle{Conclusion et faiblesses de UMAP}
	\begin{itemize}
		
		\item[$\textcolor{modernvert}{\bullet}$] Pour des datasets qui présentent une structure topologique marquée dans chaque sous groupe, les rendus de l'algorithme UMAP sont visibles et permettent bien de visualiser les clusters.\\[1cm] 
		\item[$\textcolor{red}{\bullet}$] À l'inverse d'une méthode de réduction de dimension par projection linéaire type ACP, avec UMAP les coordonnées des observations dans l'espace d'arrivée sont moins interprétables physiquement. 
		\item[$\textcolor{red}{\bullet}$] La recherche des bons paramètres \textbf{n\_neighborgs} et \textbf{min\_dist} n'est pas  évidente et ne permets pas toujours de rendre une vision globales des données initiales.  
	\end{itemize}
	
\end{frame}

\end{document}








